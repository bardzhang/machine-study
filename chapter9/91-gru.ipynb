{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d02d9d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R_t=simgoid(X_t@W_xr+H_t-1@W_hr+b_r)  X_t n*d  W_xr  d*h  W_hr h*h b_r h    n样本个数  d输入个数 h是隐藏层数\n",
    "# Z_t=simgoid(X_t@W_xz+H_t-1@W_hz+b_z)  X_t n*d W_xz  d*h  W_hz h*h b_z h\n",
    "# 候选隐状态 H_hat_t=tanh(X_t@W_xh+(R_t*H_t-1)*W_hh+b_h)\n",
    "# H_t=Z_t * H_t-1+(1-Z_t) * H_hat_t\n",
    "import sys\n",
    "sys.path.append(\"D:\\pysource\\machine-study\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "149f1e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "from torch.nn import functional as F\n",
    "\n",
    "batch_size, num_steps = 32, 35\n",
    "train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2256fe20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel():\n",
    "    def __init__(self,num_hiddens,vocab_size):\n",
    "        self.num_inputs=vocab_size\n",
    "        self.num_outputs=vocab_size\n",
    "        self.num_hiddens=num_hiddens\n",
    "        self.vocab_size=vocab_size\n",
    "        self.params=self.init_params()\n",
    "\n",
    "    def init_params(self):\n",
    "\n",
    "        def normal(size):\n",
    "            return torch.randn(size=size)*0.01\n",
    "        \n",
    "        #重置门\n",
    "        w_xr=normal((self.num_inputs,self.num_hiddens))\n",
    "        w_hr=normal((self.num_hiddens,self.num_hiddens))\n",
    "        b_r=torch.zeros(self.num_hiddens)\n",
    "        #更新门\n",
    "        w_xz=normal((self.num_inputs,self.num_hiddens))\n",
    "        w_hz=normal((self.num_hiddens,self.num_hiddens))\n",
    "        b_z=torch.zeros(self.num_hiddens)\n",
    "        #候选隐状态\n",
    "        w_xh=normal((self.num_inputs,self.num_hiddens))\n",
    "        w_hh=normal((self.num_hiddens,self.num_hiddens))\n",
    "        b_h=torch.zeros(self.num_hiddens)\n",
    "        # 输出层\n",
    "        w_hq=normal((self.num_hiddens,self.num_outputs))\n",
    "        b_q=torch.zeros(self.num_outputs)\n",
    "\n",
    "        params=[w_xr,w_hr,b_r,w_xz,w_hz,b_z,w_xh,w_hh,b_h,w_hq,b_q]\n",
    "        for p in params:\n",
    "            p.requires_grad_(True)\n",
    "        return params\n",
    "    \n",
    "    def __call__(self,inputs,state):\n",
    "        x_inputs=F.one_hot(inputs.T,self.vocab_size).to(torch.float32)\n",
    "        h=state\n",
    "        w_xr,w_hr,b_r,w_xz,w_hz,b_z,w_xh,w_hh,b_h,w_hq,b_q=self.params\n",
    "\n",
    "        outputs=[]\n",
    "        for x in x_inputs:\n",
    "            R_t=torch.sigmoid((x @ w_xr)+(h @ w_hr)+b_r)\n",
    "            Z_t=torch.sigmoid((x @ w_xz)+(h @ w_hz)+b_z)\n",
    "            h_hat_t=torch.tanh((x@w_xh)+((R_t * h)@w_hh)+b_h)\n",
    "            h=Z_t * h + (1-Z_t) * h_hat_t\n",
    "            y=h @ w_hq +b_q\n",
    "            outputs.append(y)\n",
    "        return torch.cat(outputs,dim=0),h\n",
    "    \n",
    "    def begin_state(self,batch_size):\n",
    "        return torch.zeros((batch_size,self.num_hiddens))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e3cc14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.float32\n",
      "torch.float32\n",
      "torch.float32\n",
      "torch.float32\n",
      "torch.float32\n",
      "torch.float32\n",
      "torch.float32\n",
      "torch.float32\n",
      "torch.float32\n",
      "torch.float32\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for ** or pow(): 'NoneType' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 65\u001b[39m\n\u001b[32m     63\u001b[39m num_hiddens=\u001b[32m256\u001b[39m\n\u001b[32m     64\u001b[39m net=RNNModel(num_hiddens,\u001b[38;5;28mlen\u001b[39m(vocab))\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m \u001b[43mtrain_ch8\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_iter\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 56\u001b[39m, in \u001b[36mtrain_ch8\u001b[39m\u001b[34m(net, vocab, lr, epoch, train_iter)\u001b[39m\n\u001b[32m     54\u001b[39m predict=\u001b[38;5;28;01mlambda\u001b[39;00m prefix: pred_ch8(prefix,\u001b[32m50\u001b[39m,net,vocab)\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epoch):\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     \u001b[43mtrain_epoch_ch8\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43mupdater\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[38;5;28mprint\u001b[39m(predict(\u001b[33m\"\u001b[39m\u001b[33mtime traveller\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m     58\u001b[39m \u001b[38;5;28mprint\u001b[39m(predict(\u001b[33m\"\u001b[39m\u001b[33mtraveller\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 48\u001b[39m, in \u001b[36mtrain_epoch_ch8\u001b[39m\u001b[34m(net, loss, updater, train_iter, lr)\u001b[39m\n\u001b[32m     46\u001b[39m l=loss(y_hat,y.long()).mean()\n\u001b[32m     47\u001b[39m l.backward()\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m \u001b[43mgrad_clipping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m updater(net.params,lr)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36mgrad_clipping\u001b[39m\u001b[34m(net, theta)\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[32m     25\u001b[39m     \u001b[38;5;28mprint\u001b[39m(p.dtype)\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m norm=torch.sqrt(\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m norm>theta:\n\u001b[32m     28\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m params:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[32m     25\u001b[39m     \u001b[38;5;28mprint\u001b[39m(p.dtype)\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m norm=torch.sqrt(\u001b[38;5;28msum\u001b[39m(torch.sum((\u001b[43mp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[32;43m2\u001b[39;49m)) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m params))\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m norm>theta:\n\u001b[32m     28\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m params:\n",
      "\u001b[31mTypeError\u001b[39m: unsupported operand type(s) for ** or pow(): 'NoneType' and 'int'"
     ]
    }
   ],
   "source": [
    "# 训练\n",
    "# 1. 定义损失函数\n",
    "# 2  定义梯度更新方式\n",
    "# 3  预热数据\n",
    "# 4  训练\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "def pred_ch8(prefix,pred_num,net,vocab):\n",
    "    state=net.begin_state(1)\n",
    "    outputs=[vocab[prefix[0]]]\n",
    "    get_input=lambda: torch.tensor([outputs[-1]]).reshape(1,1)\n",
    "    for y in prefix[1:]: #预热\n",
    "        _,state=net(get_input(),state)\n",
    "        outputs.append(vocab[y])\n",
    "    for _ in range(pred_num): #预测\n",
    "        y,state=net(get_input(),state)\n",
    "        outputs.append(int(y.argmax(dim=1).reshape(1)))\n",
    "    return ''.join([vocab.idx_to_token[i] for i in outputs])\n",
    "\n",
    "# 梯度裁剪  g<-min(1,theta/||g||)g\n",
    "def grad_clipping(net,theta):\n",
    "    params=net.params\n",
    "    # for p in params:\n",
    "    #     print(p.dtype)\n",
    "    norm=torch.sqrt(sum(torch.sum((p.grad**2)) for p in params))\n",
    "    if norm>theta:\n",
    "        for p in params:\n",
    "            p.grad[:]*= theta/norm\n",
    "\n",
    "def sgd(params,lr):\n",
    "    with torch.no_grad():\n",
    "        for p in params:\n",
    "            p-=lr*p.grad\n",
    "            p.grad.zero_()\n",
    "\n",
    "def train_epoch_ch8(net,loss,updater,train_iter,lr):\n",
    "    state=None\n",
    "    for X,Y in train_iter:\n",
    "        if state==None:\n",
    "            state=net.begin_state(X.shape[0])\n",
    "        else:\n",
    "            state.detach_()  #分离state\n",
    "        y=Y.T.reshape(-1)\n",
    "        y_hat,state=net(X,state)\n",
    "        l=loss(y_hat,y.long()).mean()\n",
    "        l.backward()\n",
    "        grad_clipping(net,1)\n",
    "        updater(net.params,lr)\n",
    "\n",
    "def train_ch8(net,vocab,lr,epoch,train_iter):\n",
    "    loss=nn.CrossEntropyLoss()\n",
    "    updater=sgd\n",
    "    predict=lambda prefix: pred_ch8(prefix,50,net,vocab)\n",
    "    for _ in range(epoch):\n",
    "        train_epoch_ch8(net,loss,updater,train_iter,lr)\n",
    "    print(predict(\"time traveller\"))\n",
    "    print(predict(\"traveller\"))\n",
    "\n",
    "\n",
    "epoch=500\n",
    "lr=1\n",
    "num_hiddens=256\n",
    "net=RNNModel(num_hiddens,len(vocab))\n",
    "train_ch8(net,vocab,lr,epoch,train_iter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
