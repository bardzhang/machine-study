{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-30T09:26:45.270608300Z",
     "start_time": "2025-12-30T09:26:45.261633900Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('D:\\pysource\\machine-study')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd6f2c885d2ada0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-30T09:26:52.121703Z",
     "start_time": "2025-12-30T09:26:49.192108500Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from d2l import torch as d2l\n",
    "\n",
    "batch_size, num_steps = 32, 35\n",
    "train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "786e8ffd146f9274",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-30T09:26:53.743900400Z",
     "start_time": "2025-12-30T09:26:53.734236100Z"
    }
   },
   "outputs": [],
   "source": [
    "num_hiddens=256\n",
    "rnn_layer=nn.RNN(len(vocab), num_hiddens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61ebaed5c4eaac38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-30T09:27:51.911385900Z",
     "start_time": "2025-12-30T09:27:51.567870200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 256])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state=torch.zeros((1,batch_size,num_hiddens))\n",
    "state.shape  #隐藏层数 批量大小 隐藏层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d8ba89595f9b536",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-30T09:26:55.845395100Z",
     "start_time": "2025-12-30T09:26:55.674770200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([35, 32, 256]), torch.Size([1, 32, 256]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.rand(size=(num_steps,batch_size,len(vocab)))\n",
    "y,state_new=rnn_layer(x,state)\n",
    "#步长 批量大小，隐藏层\n",
    "y.shape,state_new.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7748e3f8e78f2928",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-30T09:25:25.798184500Z",
     "start_time": "2025-12-30T09:25:25.730977Z"
    }
   },
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, num_hiddens, vocab_size):\n",
    "        super().__init__()\n",
    "        self.rnn=nn.RNN(vocab_size,num_hiddens)\n",
    "        self.vocab_size=vocab_size\n",
    "        self.hidden_nums=self.rnn.hidden_size\n",
    "        self.linear=nn.Linear(self.hidden_nums,self.vocab_size)\n",
    "\n",
    "    def forward(self,inputs,state):\n",
    "        x=F.one_hot(inputs.T,self.vocab_size).to(torch.float32) #35*32*28 32*255\n",
    "        y,state=self.rnn(x,state)\n",
    "        #outputs=self.linear(y)\n",
    "        #输出形状是步长*批量大小，隐藏层数\n",
    "        outputs=self.linear(y.reshape((-1,y.shape[-1])))\n",
    "        return outputs,state\n",
    "\n",
    "    def begin_state(self,batch_size):\n",
    "        return torch.zeros((self.rnn.num_layers,batch_size,self.hidden_nums))\n",
    "    \n",
    "\n",
    "# trnn=RNNModel(rnn_layer,len(vocab)) \n",
    "# state=trnn.begin_state(32)\n",
    "# x,y=next(iter(train_iter))\n",
    "# y,state=trnn(x,state)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3859c0c511323748",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-30T09:24:07.293739500Z",
     "start_time": "2025-12-30T09:24:06.711494400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'time travellerwwwwwwwwww'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#预测数据，把数据当成批量1 的数据处理，用输出的最后一个字母，作为输入进行预测\n",
    "def pred_ch8(prefix,pred_num,net,vocab):\n",
    "    state=net.begin_state(1)\n",
    "    outputs=[vocab[prefix[0]]]\n",
    "    get_input=lambda : torch.tensor([outputs[-1]]).reshape((1,1))\n",
    "    for i in prefix[1:]:  #预热预测数据\n",
    "        _,state=net(get_input(),state)\n",
    "        outputs.append(vocab[i])\n",
    "    for _ in range(pred_num):\n",
    "        y,state=net(get_input(),state)\n",
    "        outputs.append(int(y.argmax(dim=1)))\n",
    "\n",
    "    return ''.join([ vocab.idx_to_token[out] for out in outputs])\n",
    "\n",
    "test=RNNModel(num_hiddens,len(vocab))\n",
    "pred_ch8(\"time traveller\",10,test,vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f458f62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n",
      "time traveller after the pauserequired for the ableplyound for a\n",
      "traveller poon the milaclwtoments in time tare dinett anopt\n"
     ]
    }
   ],
   "source": [
    "def grad_clipping(net,theta):\n",
    "    # params=net.parameters()\n",
    "    # norm=torch.sqrt(sum(torch.sum(p.grad**2) for p in params))\n",
    "    params=[p for p in net.parameters() if p.requires_grad]\n",
    "    norm=torch.sqrt(sum(torch.sum(p.grad**2) for p in params))\n",
    "    # print(norm_k,' ',norm)\n",
    "    if norm>theta:\n",
    "        for p in params:\n",
    "            p.grad[:]*=theta/norm\n",
    "\n",
    "\n",
    "def train_ch8(net,loss,updater,train_iter):\n",
    "    state=None\n",
    "    ct=0\n",
    "    for X,Y in train_iter:\n",
    "        if state==None:\n",
    "            state=net.begin_state(X.shape[0])\n",
    "        else:\n",
    "            state.detach_()\n",
    "        \n",
    "        y=Y.T.reshape(-1)\n",
    "        y_hat,state=net(X,state)\n",
    "        l=loss(y_hat,y.long()).mean()\n",
    "        updater.zero_grad()\n",
    "        l.backward()\n",
    "        grad_clipping(net,1)\n",
    "        updater.step()\n",
    "        ct=ct+1\n",
    "    return ct\n",
    "        \n",
    "\n",
    "def train_rnn(epoch,net,lr,train_iter,vocab):\n",
    "    loss=nn.CrossEntropyLoss()\n",
    "    updater=torch.optim.SGD(net.parameters(),lr)\n",
    "    \n",
    "    predict=lambda prefix:pred_ch8(prefix,50,net,vocab)\n",
    "    count=0\n",
    "    for i in range(epoch):\n",
    "        count+=train_ch8(net,loss,updater,train_iter);\n",
    "    print(count)\n",
    "    print(predict(\"time traveller\"))\n",
    "    print(predict(\"traveller\"))\n",
    "\n",
    "epoch=512\n",
    "lr=1\n",
    "num_hiddens=256\n",
    "net=RNNModel(num_hiddens,len(vocab))\n",
    "train_rnn(epoch,net,lr,train_iter,vocab)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
