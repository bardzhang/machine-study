{
 "cells": [
  {
   "cell_type": "code",
   "id": "f8c80536",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-30T06:38:15.112360800Z",
     "start_time": "2025-12-30T06:38:15.042136100Z"
    }
   },
   "source": [
    "# 1. 读取文件\n",
    "# 2. 词元化 将文文本数据拆分成字符或者单词\n",
    "# 3. 建立词表  词表包含单词或者字符的频率， 从id到单词或者字符的索引 数组表示，从单词或者字符的索引到单词 字典表示\n",
    "#              文章的长度__len__  __getitem__ 返回token所在的索引  根据索引返回对应的单词或者字符 用<unk>表示空\n",
    "\n",
    "import re \n",
    "\n",
    "def readfile():\n",
    "    lines=[]\n",
    "    with open(\"../data/timemachine.txt\") as f:\n",
    "        for line in f:\n",
    "            lines.append(re.sub(\"[^A-Za-z]+\",' ',line).strip().lower())\n",
    "    return lines\n",
    "\n",
    "lines=readfile()\n",
    "for i in range(2):\n",
    "    print(lines[i])\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the time machine by h g wells\n",
      "\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "af537fb7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-30T06:38:15.157472600Z",
     "start_time": "2025-12-30T06:38:15.115638300Z"
    }
   },
   "source": [
    "def tokenize(lines,type='word'):\n",
    "    if type=='word':\n",
    "        return [ line.split() for line in lines]\n",
    "    elif type=='char':\n",
    "        return [list(line) for line in lines]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "tokens=tokenize(lines)\n",
    "for i in range(11):\n",
    "    print(tokens[i])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'time', 'machine', 'by', 'h', 'g', 'wells']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "['i']\n",
      "[]\n",
      "[]\n",
      "['the', 'time', 'traveller', 'for', 'so', 'it', 'will', 'be', 'convenient', 'to', 'speak', 'of', 'him']\n",
      "['was', 'expounding', 'a', 'recondite', 'matter', 'to', 'us', 'his', 'grey', 'eyes', 'shone', 'and']\n",
      "['twinkled', 'and', 'his', 'usually', 'pale', 'face', 'was', 'flushed', 'and', 'animated', 'the']\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "5194cb29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-30T06:38:15.186796800Z",
     "start_time": "2025-12-30T06:38:15.158469Z"
    }
   },
   "source": [
    "import collections\n",
    "\n",
    "class Vocab():\n",
    "    def __init__(self,tokens):\n",
    "        words=[word for token in tokens for word in token]\n",
    "        counter=collections.Counter(words)\n",
    "        self._token_freq=sorted(counter.items(),key=lambda x: x[1],reverse=True)\n",
    "        \n",
    "        self.idx_to_token=['<unk>']\n",
    "        self.token_to_idx={0:'<unk>'}\n",
    "        for token,freq in self._token_freq:\n",
    "            if token not in self.token_to_idx:\n",
    "                self.idx_to_token.append(token)\n",
    "                self.token_to_idx[token]=len(self.idx_to_token)-1\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token)\n",
    "    \n",
    "    def __getitem__(self,tokens):\n",
    "        if not isinstance(tokens,(list,tuple)):\n",
    "            return self.token_to_idx.get(tokens,self.unk)\n",
    "        return [self.token_to_idx.get(token,self.unk) for token in tokens]\n",
    "\n",
    "    def to_tokens(self,indices):\n",
    "        return [ self.idx_to_token[index] for index in indices]\n",
    "\n",
    "    @property\n",
    "    def unk(self):\n",
    "        return 0\n",
    "\n",
    "    @property\n",
    "    def token_freq(self):\n",
    "        return self._token_freq\n",
    "    \n",
    "vocab=Vocab(tokens)\n",
    "print(vocab.token_freq[:10])\n",
    "print(list(vocab.token_to_idx.items())[:10])\n",
    "for i in range(10):\n",
    "    print(\"文本：\",tokens[i])\n",
    "    print(\"索引：\",vocab[tokens[i]])\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 2261), ('i', 1267), ('and', 1245), ('of', 1155), ('a', 816), ('to', 695), ('was', 552), ('in', 541), ('that', 443), ('my', 440)]\n",
      "[(0, '<unk>'), ('the', 1), ('i', 2), ('and', 3), ('of', 4), ('a', 5), ('to', 6), ('was', 7), ('in', 8), ('that', 9)]\n",
      "文本： ['the', 'time', 'machine', 'by', 'h', 'g', 'wells']\n",
      "索引： [1, 19, 50, 40, 2183, 2184, 400]\n",
      "文本： []\n",
      "索引： []\n",
      "文本： []\n",
      "索引： []\n",
      "文本： []\n",
      "索引： []\n",
      "文本： []\n",
      "索引： []\n",
      "文本： ['i']\n",
      "索引： [2]\n",
      "文本： []\n",
      "索引： []\n",
      "文本： []\n",
      "索引： []\n",
      "文本： ['the', 'time', 'traveller', 'for', 'so', 'it', 'will', 'be', 'convenient', 'to', 'speak', 'of', 'him']\n",
      "索引： [1, 19, 71, 16, 37, 11, 115, 42, 680, 6, 586, 4, 108]\n",
      "文本： ['was', 'expounding', 'a', 'recondite', 'matter', 'to', 'us', 'his', 'grey', 'eyes', 'shone', 'and']\n",
      "索引： [7, 1420, 5, 2185, 587, 6, 126, 25, 330, 127, 439, 3]\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "13273019",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-30T06:38:15.260554600Z",
     "start_time": "2025-12-30T06:38:15.189002200Z"
    }
   },
   "source": [
    "def load_corpus_time_machine(maxtokens=10000):\n",
    "    lines=readfile()\n",
    "    tokens=tokenize(lines,'char')\n",
    "    vocab=Vocab(tokens)\n",
    "\n",
    "    corpus=[vocab[ch] for token in tokens for ch in token]\n",
    "    if maxtokens>0:\n",
    "        return corpus[:maxtokens],vocab\n",
    "    return corpus,vocab\n",
    "\n",
    "corpus,vocab=load_corpus_time_machine()\n",
    "len(corpus),len(vocab)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "63aba7a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-30T06:38:15.297323500Z",
     "start_time": "2025-12-30T06:38:15.262143200Z"
    }
   },
   "source": [
    "import random\n",
    "import torch\n",
    "\n",
    "def seq_data_iter_random(corpus,batch_size,num_steps):\n",
    "\n",
    "    corpus=corpus[random.randint(0,num_steps-1):]\n",
    "\n",
    "    num_subseq=(len(corpus)-1) // num_steps\n",
    "\n",
    "    seq_indices=list(range(0,num_subseq*num_steps,num_steps))\n",
    "\n",
    "    random.shuffle(seq_indices)\n",
    "\n",
    "    def data(pos):\n",
    "        return corpus[pos:pos+num_steps]\n",
    "\n",
    "    num_batch= len(seq_indices) // batch_size\n",
    "    for i in range(0,num_batch*batch_size,batch_size):\n",
    "\n",
    "        seq_sub_indices=seq_indices[i:i+batch_size]\n",
    "        X=[data(j) for j in seq_sub_indices]\n",
    "        Y=[data(j+1) for j in seq_sub_indices]\n",
    "        yield torch.tensor(X),torch.tensor(Y)\n",
    "\n",
    "    \n",
    "myseq=list(range(35))\n",
    "data_iter=seq_data_iter_random(myseq,2,5)\n",
    "for x,y in data_iter:\n",
    "    print(x,'\\n',y)\n",
    "           "
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[24, 25, 26, 27, 28],\n",
      "        [ 4,  5,  6,  7,  8]]) \n",
      " tensor([[25, 26, 27, 28, 29],\n",
      "        [ 5,  6,  7,  8,  9]])\n",
      "tensor([[29, 30, 31, 32, 33],\n",
      "        [19, 20, 21, 22, 23]]) \n",
      " tensor([[30, 31, 32, 33, 34],\n",
      "        [20, 21, 22, 23, 24]])\n",
      "tensor([[14, 15, 16, 17, 18],\n",
      "        [ 9, 10, 11, 12, 13]]) \n",
      " tensor([[15, 16, 17, 18, 19],\n",
      "        [10, 11, 12, 13, 14]])\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "ed5cbe06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-30T06:38:15.328537Z",
     "start_time": "2025-12-30T06:38:15.298761200Z"
    }
   },
   "source": [
    "def seq_data_iter_seq(corpus,batch_size,num_steps):\n",
    "    offset=random.randint(0,num_steps)\n",
    "    num_total=((len(corpus)-offset-1)//batch_size)*batch_size\n",
    "    xs=torch.tensor(corpus[offset:num_total+offset])\n",
    "    ys=torch.tensor(corpus[offset+1:num_total+offset+1])\n",
    "    xs,ys=xs.reshape(batch_size,-1),ys.reshape(batch_size,-1)\n",
    "    num_batch=xs.shape[1]//num_steps\n",
    "    for i in range(0,num_batch*num_steps,num_steps):\n",
    "        x=xs[:,i:i+num_steps]\n",
    "        y=ys[:,i:i+num_steps]\n",
    "        yield x,y\n",
    "\n",
    "data_iter=seq_data_iter_seq(myseq,2,5)\n",
    "for x,y in data_iter:\n",
    "    print(x,'\\n',y)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5,  6,  7,  8,  9],\n",
      "        [19, 20, 21, 22, 23]]) \n",
      " tensor([[ 6,  7,  8,  9, 10],\n",
      "        [20, 21, 22, 23, 24]])\n",
      "tensor([[10, 11, 12, 13, 14],\n",
      "        [24, 25, 26, 27, 28]]) \n",
      " tensor([[11, 12, 13, 14, 15],\n",
      "        [25, 26, 27, 28, 29]])\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "29243a96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-30T06:38:15.406987300Z",
     "start_time": "2025-12-30T06:38:15.330537500Z"
    }
   },
   "source": [
    "class SeqData:\n",
    "    def __init__(self,batch_size,num_steps,use_random_iter=False,maxtokens=10000):\n",
    "        if use_random_iter:\n",
    "            self.load_data_fn=seq_data_iter_random\n",
    "        else:\n",
    "            self.load_data_fn=seq_data_iter_seq\n",
    "        self.batch_size=batch_size\n",
    "        self.num_steps=num_steps\n",
    "        self.corpus,self.vocab=load_corpus_time_machine(maxtokens)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self.load_data_fn(self.corpus,self.batch_size,self.num_steps)\n",
    "\n",
    "\n",
    "data_iter=SeqData(32,35,)\n",
    "len(list(data_iter))"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "abf134fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-30T06:38:15.442487900Z",
     "start_time": "2025-12-30T06:38:15.408988900Z"
    }
   },
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "X=torch.arange(10).reshape((2,5))\n",
    "print(X)\n",
    "test=F.one_hot(X.T,len(vocab))\n",
    "print(test.shape)\n",
    "print(test)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2, 3, 4],\n",
      "        [5, 6, 7, 8, 9]])\n",
      "torch.Size([5, 2, 28])\n",
      "tensor([[[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0]],\n",
      "\n",
      "        [[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0]]])\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "6f1087a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-30T06:38:15.466294600Z",
     "start_time": "2025-12-30T06:38:15.444487200Z"
    }
   },
   "source": [
    "#0 参数设定 隐藏层255 词大小28 步长5\n",
    "#1 初始化模型参数 x 2*28  w_xh 28*255 w_hh 255*255 b_h 255  h_t 2*255   w_hq 255*28  b_q 28 \n",
    "#2 初始化 h_0 参数  \n",
    "#3 实现模型  h_t=tanh(x*w_xh+h_t-1*w_hh+b_h)  o=h_t*W_hq+b_q  \n",
    "   # 原本x是批次大小*时间序列  转换成时间序列 批次大小 词表大小（独热编码的形式），的数据 在通过循环时间序列计算，最终将结果组合并拼接\n",
    "class RNNModel:\n",
    "   def __init__(self,vocab_size,hiddens_num):\n",
    "      self.vocab_size=vocab_size\n",
    "      self.inputs_num=self.vocab_size\n",
    "      self.hiddens_num=hiddens_num\n",
    "      self.outputs_num=self.vocab_size\n",
    "      self.params=self.init_params()\n",
    "\n",
    "   def init_params(self):\n",
    "      #隐藏层\n",
    "      w_xh=torch.randn(size=(self.inputs_num,self.hiddens_num))*0.01\n",
    "      w_hh=torch.randn(size=(self.hiddens_num,self.hiddens_num))*0.01\n",
    "      b_h=torch.zeros(self.hiddens_num)\n",
    "      #输出层\n",
    "      w_hq=torch.randn(size=(self.hiddens_num,self.outputs_num))*0.01\n",
    "      b_q=torch.zeros(self.outputs_num)\n",
    "\n",
    "      params=[w_xh,w_hh,b_h,w_hq,b_q]\n",
    "      for p in params:\n",
    "         p.requires_grad_(True)\n",
    "      return params\n",
    "\n",
    "   def begin_state(self,batch_size):\n",
    "      return torch.zeros((batch_size,self.hiddens_num))\n",
    "   \n",
    "   def __call__(self,x,state):# 32*35 -> 35 * 32 *28\n",
    "      xhot=F.one_hot(x.T,self.vocab_size).type(torch.float32)\n",
    "      w_xh,w_hh,b_h,w_hq,b_q=self.params\n",
    "      h=state\n",
    "      outputs=[]\n",
    "      for inx in xhot:\n",
    "         #print(inx.shape,w_xh.shape,h.shape,w_hh.shape,b_h.shape)\n",
    "         h=torch.tanh(torch.mm(inx,w_xh)+torch.mm(h,w_hh)+b_h)\n",
    "         y=torch.mm(h,w_hq)+b_q\n",
    "         outputs.append(y)\n",
    "      #print(outputs)\n",
    "      return torch.cat(outputs,dim=0),h\n",
    "\n",
    "\n",
    "# batch_size=32\n",
    "# num_steps=35\n",
    "# hiddens_num=256\n",
    "# train_iter,vocab=load_data_time_machine(batch_size,num_steps)\n",
    "# xs,ys=next(iter(train_iter))\n",
    "# print(xs.shape,ys.shape)\n",
    "# net=RNNModel(len(vocab),hiddens_num)\n",
    "# state=net.begin_state(batch_size)\n",
    "# outputs,state=net(xs,state)\n",
    "# print(outputs.shape,state.shape)\n"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "a57b0e0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-30T06:38:15.487741Z",
     "start_time": "2025-12-30T06:38:15.468294300Z"
    }
   },
   "source": [
    "def pred_ch8(prefix,pred_num,net,vocab):\n",
    "    state=net.begin_state(1)\n",
    "    outputs=[vocab[prefix[0]]]\n",
    "    get_input=lambda: torch.tensor([outputs[-1]]).reshape(1,1)\n",
    "    for y in prefix[1:]: #预热\n",
    "        _,state=net(get_input(),state)\n",
    "        outputs.append(vocab[y])\n",
    "    for _ in range(pred_num): #预测\n",
    "        y,state=net(get_input(),state)\n",
    "        outputs.append(int(y.argmax(dim=1).reshape(1)))\n",
    "    return ''.join([vocab.idx_to_token[i] for i in outputs])\n",
    "\n",
    "#pred_ch8(\"time traveller\",10,net,vocab)\n"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-30T06:38:15.509156400Z",
     "start_time": "2025-12-30T06:38:15.488741500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 训练\n",
    "# 1. 定义损失函数\n",
    "# 2  定义梯度更新方式\n",
    "# 3  预热数据\n",
    "# 4  训练\n",
    "from torch import nn\n",
    "\n",
    "# 梯度裁剪  g<-min(1,theta/||g||)g\n",
    "def grad_clipping(net,theta):\n",
    "    params=net.params\n",
    "    norm=torch.sqrt(sum(torch.sum((p.grad**2)) for p in params))\n",
    "    if norm>theta:\n",
    "        for p in params:\n",
    "            p.grad[:]*= theta/norm\n",
    "\n",
    "def sgd(params,lr):\n",
    "    with torch.no_grad():\n",
    "        for p in params:\n",
    "            p-=lr*p.grad\n",
    "            p.grad.zero_()\n",
    "\n",
    "def train_epoch_ch8(net,loss,updater,train_iter,lr):\n",
    "    state=None\n",
    "    for X,Y in train_iter:\n",
    "        if state==None:\n",
    "            state=net.begin_state(X.shape[0])\n",
    "        else:\n",
    "            state.detach_()  #分离state\n",
    "        y=Y.T.reshape(-1)\n",
    "        y_hat,state=net(X,state)\n",
    "        l=loss(y_hat,y.long()).mean()\n",
    "        l.backward()\n",
    "        grad_clipping(net,1)\n",
    "        updater(net.params,lr)\n",
    "\n",
    "def train_ch8(net,vocab,lr,epoch,train_iter):\n",
    "    loss=nn.CrossEntropyLoss()\n",
    "    updater=sgd\n",
    "    predict=lambda prefix: pred_ch8(prefix,50,net,vocab)\n",
    "    for _ in range(epoch):\n",
    "        train_epoch_ch8(net,loss,updater,train_iter,lr)\n",
    "    print(predict(\"time traveller\"))\n",
    "    print(predict(\"traveller\"))\n"
   ],
   "id": "a3eac96f07381172",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-30T06:39:38.240360600Z",
     "start_time": "2025-12-30T06:38:15.510158100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size=32\n",
    "num_steps=35\n",
    "hiddens_num=512\n",
    "lr=1\n",
    "epoch=500\n",
    "train_iter=SeqData(batch_size,num_steps)\n",
    "#print(len(list(train_iter)))\n",
    "vocab=train_iter.vocab\n",
    "net=RNNModel(len(vocab),hiddens_num)\n",
    "train_ch8(net,vocab,lr,epoch,train_iter)"
   ],
   "id": "695968d80a4c4158",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time traveller for so it will be convenient to speak of himwas e\n",
      "travelleryou can show black is white by argument said filby\n"
     ]
    }
   ],
   "execution_count": 24
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
